grafana.enabled: false
promtail.enabled: true

loki:
  image:
    tag: 2.3.0
  # Loki log 알림 규칙
  config:
    ruler:
      storage:
        type: local
        local:
          directory: /rules
      rule_path: /tmp/scratch
      alertmanager_url: http://loki-prometheus-alertmanager:80
      ring:
        kvstore:
          store: inmemory
      enable_api: true
  alerting_groups:
    - name: Control-Plane
      rules:
        - alert: Control-Plane component
          expr: |
            sum by (component) (
              rate({tier="control-plane"}[30s]
                |= "error"
                != "[watcher.go:229] watch chan error"
            )
            ) > 0
          for: 0s
          labels:
            severity: Critical
            summary: "Control-Plane error"
            description: "컨트롤 플레인 컴포넌트 error 로그 발생"
          annotations:
            componet: "{{ $labels.component }}"
            dashboard: "http://grafana.choshsh.com/d/JqglEFN7z/kube-control-plane-log?var-searchable_pattern=error&from=now-5m&to=now"
    - name: CoreDNS
      rules:
        - alert: coredns
          expr: rate({k8s_app="kube-dns"}[30s] |= "error") > 0
          for: 0s
          labels:
            severity: Critical
            summary: "CoreDNS error"
            description: "CoreDNS error 로그 발생"
          annotations:
            container: "{{ $labels.container }}"
            dashboard: "http://grafana.choshsh.com/d/JqglEFN7z/kube-control-plane-log?var-searchable_pattern=error&from=now-5m&to=now"

prometheus:
  enabled: true
  alertmanager:
    persistentVolume:
      enabled: true
      storageClass: nfs-client
      accessModes: ["ReadWriteMany"]

  server:
    persistentVolume:
      enabled: true
      storageClass: nfs-client
      accessModes: ["ReadWriteMany"]
    global:
      scrape_interval: 15s
      scrape_timeout: 10s
      evaluation_interval: 15s

  # custom scrape
  # probe metric 수집을 위한 sd 설정
  extraScrapeConfigs: |
    - job_name: "kubernetes-nodes-probes"
      metrics_path: /metrics/probes
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      kubernetes_sd_configs:
        - role: node
      relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/$1/proxy/metrics/probes

  # Prometheus Metric 알림 규칙
  serverFiles:
    alerting_rules.yml:
      groups:
        - name: Node
          rules:
            # Node 다운
            - alert: Node Down
              expr: up{job="kubernetes-nodes"} < 1
              for: 1m
              labels:
                severity: Critical
                summary: "Node Down"
                description: "1분 동안 노드 Down 상태"
              annotations:
                hostname: "{{ $labels.kubernetes_io_hostname }}"
                dashboard: "http://grafana.choshsh.com/d/4b545447f/kubernetes-all-in-one-cluster-monitoring-kr?orgId=1&var-node={{ $labels.kubernetes_io_hostname }}"
            # Node CPU 높음
            - alert: Node high CPU load
              expr: |
                (
                  1 - avg by (instance,kubernetes_node) (
                    irate(node_cpu_seconds_total{mode="idle"}[5m])
                  )
                ) * 100 > 80
              for: 5m
              labels:
                severity: Warning
                summary: "Node CPU high"
                description: "5분 동안 노드 CPU 사용량 80% 초과"
              annotations:
                hostname: "{{ $labels.kubernetes_node }}"
                instance: "{{ $labels.instance }}"
                dashboard: "http://grafana.choshsh.com/d/4b545447f/kubernetes-all-in-one-cluster-monitoring-kr?orgId=1&var-node={{ $labels.kubernetes_node }}"
        - name: Deploy
          rules:
            # Deployment 다운
            - alert: Deployment Down
              expr: |
                kube_deployment_status_replicas_available < 1 
                and
                time() - kube_deployment_created > 120
              for: 1m
              labels:
                severity: Critical
                summary: "Deployment Down"
                description: "1분 동안 available pod 0개"
              annotations:
                namespace: "{{ $labels.namespace }}"
                deployment: "{{ $labels.deployment }}"
                dashboard: "http://grafana.choshsh.com/d/XeS0yvN7z/kube-all-resource-log?orgId=1&refresh=10s&from=now-10m&to=now"
            # Statefulset 다운
            - alert: Statefulset Down
              expr: kube_statefulset_status_replicas_current < 1
              for: 1m
              labels:
                severity: Critical
                summary: "Statefulset Down"
                description: "1분 동안 available pod 0개"
              annotations:
                namespace: "{{ $labels.namespace }}"
                statefulset: "{{ $labels.statefulset }}"
                dashboard: "http://grafana.choshsh.com/d/XeS0yvN7z/kube-all-resource-log?orgId=1&refresh=10s&from=now-10m&to=now"
        - name: JVM
          rules:
            # JVM HEAP 메모리 높음
            - alert: Heap memory high
              expr: |
                sum by (kubernetes_name) (
                  jvm_memory_used_bytes{area="heap"}
                )
                /
                sum by (kubernetes_name) (
                  jvm_memory_max_bytes{area="heap"}
                ) * 100 > 80
              for: 1m
              labels:
                severity: Warning
                summary: "Heap memory high"
                description: "1분 동안 heap 메모리 사용률 80% 초과 "
              annotations:
                service: "{{ $labels.kubernetes_name }}"
                dashboard: "http://grafana.choshsh.com/d/ku9BHmOnz/jvm-micrometer?orgId=1&var-application={{ $labels.kubernetes_name }}"

  # Alertmanager 알림 설정
  alertmanagerFiles:
    alertmanager.yml:
      global: {}
      # slack_api_url: "slack url"

      receivers:
        - name: slack-default
          slack_configs:
            - channel: "#devops"
              send_resolved: true
              title_link: "http://loki-prometheus-alertmanager.choshsh.com/#/alerts"
              title: |-
                [{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .CommonLabels.alertname }}
              text: >-
                {{ range .Alerts -}}
                *Alert:* {{ .Labels.summary }} - `{{ .Labels.severity }}`

                *Description:* {{ .Labels.description }}

                *Details:*
                  {{ range $key, $value := .Annotations -}}
                  • *{{ $key }}:* {{ $value }}
                  {{ end }}
                {{ end }}

      route:
        receiver: slack-default
        group_by: [alertname]
        group_wait: 0s # 처음 알림을 보내기 전 대기시간
        group_interval: 1m # 해당 그룹에 이미 알림이 있을 때 대기시간
        repeat_interval: 3h # 성공한 알림 다시 보냄
