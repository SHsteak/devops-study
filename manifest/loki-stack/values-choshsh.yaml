loki:
  image:
    tag: 2.3.0

grafana.enabled: false
promtail.enabled: true

prometheus:
  enabled: true
  alertmanager:
    persistentVolume:
      enabled: true
      storageClass: nfs-client
      accessModes: ["ReadWriteMany"]

  server:
    persistentVolume:
      enabled: true
      storageClass: nfs-client
      accessModes: ["ReadWriteMany"]
    global:
      scrape_interval: 15s
      scrape_timeout: 10s
      evaluation_interval: 15s

  # custom scrape
  # probe metric 수집을 위한 sd 설정
  extraScrapeConfigs: |
    - job_name: "kubernetes-nodes-probes"
      metrics_path: /metrics/probes
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      kubernetes_sd_configs:
        - role: node
      relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/$1/proxy/metrics/probes

  # Prometheus 알람 규칙
  serverFiles:
    alerting_rules.yml:
      groups:
        - name: Node
          rules:
            # Node 다운
            - alert: Node Down
              expr: up{job="kubernetes-nodes"} < 1
              for: 10s
              labels:
                severity: Critical
                summary: "Node Down"
                description: "{{ $labels.deployment }} 10초 동안 {{ $labels.kubernetes_io_hostname }} 노드 Down 상태"
              annotations:
                hostname: "{{ $labels.kubernetes_io_hostname }}"
                dashboard: "http://grafana.choshsh.com/d/4b545447f/kubernetes-all-in-one-cluster-monitoring-kr?orgId=1&var-node={{ $labels.kubernetes_io_hostname }}"
            # Node CPU 높음
            - alert: Node high CPU load
              expr: sum by (instance, kubernetes_node) (irate(node_cpu_seconds_total{mode!~"guest.*|idle|iowait"}[5m])) * 100 > 90
              for: 5m
              labels:
                severity: Warning
                summary: "Node CPU high"
                description: "{{ $labels.deployment }} 5분 동안 {{ $labels.kubernetes_node }} 노드 CPU 사용량 90% 초과"
              annotations:
                hostname: "{{ $labels.kubernetes_node }}"
                instance: "{{ $labels.instance }}"
                dashboard: "http://grafana.choshsh.com/d/4b545447f/kubernetes-all-in-one-cluster-monitoring-kr?orgId=1&var-node={{ $labels.kubernetes_node }}"
        - name: Deploy
          rules:
            # Deployment 다운
            - alert: Deployment Down
              expr: kube_deployment_status_replicas_available < 1
              for: 10s
              labels:
                severity: Critical
                summary: "Deployment Down"
                description: "10초 동안 available pod {{ $value }}개"
              annotations:
                namespace: "{{ $labels.namespace }}"
                deployment: "{{ $labels.deployment }}"
                dashboard: "http://grafana.choshsh.com/d/XeS0yvN7z/kube-all-resource-log?orgId=1&refresh=10s&from=now-10m&to=now"
            # Statefulset 다운
            - alert: Statefulset Down
              expr: kube_statefulset_status_replicas_current < 1
              for: 10s
              labels:
                severity: Critical
                summary: "Statefulset Down"
                description: "10초 동안 available pod {{ $value }}개"
              annotations:
                namespace: "{{ $labels.namespace }}"
                statefulset: "{{ $labels.statefulset }}"
                dashboard: "http://grafana.choshsh.com/d/XeS0yvN7z/kube-all-resource-log?orgId=1&refresh=10s&from=now-10m&to=now"
        - name: JVM
          rules:
            # JVM HEAP 메모리 높음
            - alert: Heap memory high
              expr: sum by (kubernetes_name) (jvm_memory_used_bytes{area="heap"}) / sum by (kubernetes_name) (jvm_memory_max_bytes{area="heap"}) * 100 > 80
              for: 1m
              labels:
                severity: Warning
                summary: "Heap memory high"
                description: "1분 동안 heap 메모리 사용률 80% 초과 "
              annotations:
                service: "{{ $labels.kubernetes_name }}"
                dashboard: "http://grafana.choshsh.com/d/ku9BHmOnz/jvm-micrometer?orgId=1&var-application={{ $labels.kubernetes_name }}"

  # Alertmanager 알람 설정
  alertmanagerFiles:
    alertmanager.yml:
      global: {}
      # slack_api_url: "slack url"

      receivers:
        - name: slack-default
          slack_configs:
            - channel: "#devops"
              send_resolved: true
              title_link: "http://loki-prometheus-alertmanager.choshsh.com/#/alerts"
              title: |-
                [{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .CommonLabels.alertname }}
              text: >-
                {{ range .Alerts -}}
                *Alert:* {{ .Labels.summary }} - `{{ .Labels.severity }}`

                *Description:* {{ .Labels.description }}

                *Details:*
                  {{ range $key, $value := .Annotations -}}
                  • *{{ $key }}:* {{ $value }}
                  {{ end }}
                {{ end }}

      route:
        receiver: slack-default
        group_by: [alertname]
        group_wait: 10s
        group_interval: 10s
        repeat_interval: 3h
